{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pytorch-lightning\n",
    "! pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics \n",
    "from torchmetrics.functional import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(pl.LightningModule):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.l1 = nn.Linear(28 * 28, 64)\n",
    "    self.l2 = nn.Linear(64, 64)\n",
    "    self.l3 = nn.Linear(64, 10)\n",
    "    self.do = nn.Dropout(0.1)\n",
    "\n",
    "    self.loss = nn.CrossEntropyLoss()\n",
    "    self.accuracy = torchmetrics.Accuracy()\n",
    "  \n",
    "  def forward(self, x):\n",
    "    h1 = nn.functional.relu(self.l1(x))\n",
    "    h2 = nn.functional.relu(self.l2(h1))\n",
    "    do = self.do(h2 +h1)\n",
    "    logits = self.l3(do)\n",
    "    return logits\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    optimizer = optim.SGD(self.parameters(), lr=1e-2)\n",
    "    return optimizer\n",
    "\n",
    "# == ESTE CODIGO ES SOLO PARA MULTI GPU ==\n",
    "  # para entrenar con multi gpu a los parametros de pl.Trainer se suman\n",
    "  # gpus=8, num_nodes=32\n",
    "  # num_nodes es la cantidad de compus con 8 gpus que tenemos\n",
    "\n",
    "  def prepare_data(self):\n",
    "    # esto solo se va a ejecutar una vez, no en todas las gpu\n",
    "    # aca hace lo que quieras que pase una vez\n",
    "    # este metodo tiene sentido si todos los nodos comparten el mismo file system\n",
    "    # si todos los nodos tienen su propio file system, lightning lo va a autodetectar y ejecutar este metodo por cada uno de ellos\n",
    "    datasets.MNIST('data', train=True, download=False, transform=transforms.ToTensor())\n",
    "\n",
    "  def setup(self):\n",
    "    # aca podemos girar, normalizar imagenes, hacer pre processing del dataset \n",
    "\n",
    "    # setup se corre en cada gpu asi que podemos asignar estado cuando entrenas en multi-gpu estas poniendo una copia del modelo en cada gpu\n",
    "    dataset = datasets.MNIST('data', train=True, download=False, transform=transforms.ToTensor())\n",
    "    self.train, self.val = random_split(dataset, [55000, 5000])\n",
    "# ==== \n",
    "\n",
    "  def train_dataloader(self):\n",
    "    # esto acopla la data al modelo lo cual no siempre es deseable \n",
    "    # ponele que estas entrenando un imageNet para clasificar 5 clases\n",
    "    # esta bueno que eso este definido en el modelo, queda lindo y limpio\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(self.train, batch_size=32)\n",
    "    return train_loader\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    # estos metodos no se llaman cuando se instancia la clase\n",
    "    # lightning implementa lazy loading, solo cuando se ejecuta el loop de validacion, se ejecuta el data loader.\n",
    "\n",
    "    # esto acopla la data al modelo lo cual no siempre es deseable \n",
    "    # ponele que estas entrenando un imageNet para clasificar 5 clases\n",
    "    # esta bueno que eso este definido en el modelo, queda lindo y limpio\n",
    "    val_loader = DataLoader(self.val, batch_size=32)\n",
    "    return val_loader\n",
    "\n",
    "  def training_step(self, batch):\n",
    "    x, y = batch\n",
    "    # x = batchsize * 1 * 28 * 28\n",
    "    b = x.size(0)\n",
    "    x = x.view(b, -1)\n",
    "    # 1) forward\n",
    "    logits = self(x)\n",
    "    # 2) compute the objective function\n",
    "    J = self.loss(logits, y)\n",
    "    self.accuracy(logits, y)\n",
    "    self.log(f\"train_acc_step\", self.accuracy, on_epoch=True)\n",
    "    return {'loss': J}\n",
    "\n",
    "  def training_epoch_end(self, batch_parts):\n",
    "    acc = self.accuracy.compute()\n",
    "    self.log('train_acc_epoch', acc)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "   results = self.training_step(batch)\n",
    "  \n",
    "  def validation_epoch_end(self, validation_step_outputs):\n",
    "    avg_val_loss = torch.tensor([x['loss'] for x in validation_step_outputs]).mean()\n",
    "    return\n",
    "\n",
    " \n",
    "\n",
    "model = ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /home/gocandra/workspace/lightning/lightning_logs\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/gocandra/workspace/lightning/e02_MNIST_pytorch_to_lightning.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gocandra/workspace/lightning/e02_MNIST_pytorch_to_lightning.ipynb#ch0000007?line=0'>1</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gocandra/workspace/lightning/e02_MNIST_pytorch_to_lightning.ipynb#ch0000007?line=1'>2</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:770\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[39mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 770\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    771\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    772\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:723\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    722\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 723\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    724\u001b[0m \u001b[39m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:811\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    807\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    808\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    809\u001b[0m     ckpt_path, model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    810\u001b[0m )\n\u001b[0;32m--> 811\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    813\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    814\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1217\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger_connector\u001b[39m.\u001b[39mreset_metrics()\n\u001b[1;32m   1216\u001b[0m \u001b[39m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49msetup(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   1219\u001b[0m \u001b[39m# hook\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39m==\u001b[39m TrainerFn\u001b[39m.\u001b[39mFITTING:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/strategies/single_device.py:72\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.setup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup\u001b[39m(\u001b[39mself\u001b[39m, trainer: pl\u001b[39m.\u001b[39mTrainer) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_to_device()\n\u001b[0;32m---> 72\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msetup(trainer)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py:139\u001b[0m, in \u001b[0;36mStrategy.setup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39m\"\"\"Setup plugins for the trainer fit and creates optimizers.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \n\u001b[1;32m    135\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m    trainer: the trainer instance\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39msetup(trainer)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup_optimizers(trainer)\n\u001b[1;32m    140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msetup_precision_plugin()\n\u001b[1;32m    141\u001b[0m optimizers_to_device(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py:128\u001b[0m, in \u001b[0;36mStrategy.setup_optimizers\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (TrainerFn\u001b[39m.\u001b[39mFITTING, TrainerFn\u001b[39m.\u001b[39mTUNING):\n\u001b[1;32m    127\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_scheduler_configs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_frequencies \u001b[39m=\u001b[39m _init_optimizers_and_lr_schedulers(\n\u001b[1;32m    129\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlightning_module\n\u001b[1;32m    130\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py:180\u001b[0m, in \u001b[0;36m_init_optimizers_and_lr_schedulers\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39m\"\"\"Calls `LightningModule.configure_optimizers` and parses and validates the output.\"\"\"\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[39massert\u001b[39;00m model\u001b[39m.\u001b[39mtrainer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m optim_conf \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_lightning_module_hook(\u001b[39m\"\u001b[39;49m\u001b[39mconfigure_optimizers\u001b[39;49m\u001b[39m\"\u001b[39;49m, pl_module\u001b[39m=\u001b[39;49mmodel)\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m optim_conf \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     rank_zero_warn(\n\u001b[1;32m    184\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    185\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1595\u001b[0m, in \u001b[0;36mTrainer._call_lightning_module_hook\u001b[0;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1592\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[1;32m   1594\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1595\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1597\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1598\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "\u001b[1;32m/home/gocandra/workspace/lightning/e02_MNIST_pytorch_to_lightning.ipynb Cell 3'\u001b[0m in \u001b[0;36mResNet.configure_optimizers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gocandra/workspace/lightning/e02_MNIST_pytorch_to_lightning.ipynb#ch0000003?line=17'>18</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconfigure_optimizers\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gocandra/workspace/lightning/e02_MNIST_pytorch_to_lightning.ipynb#ch0000003?line=18'>19</a>\u001b[0m   optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39;49mSGD(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparameters, lr\u001b[39m=\u001b[39;49m\u001b[39m1e-2\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gocandra/workspace/lightning/e02_MNIST_pytorch_to_lightning.ipynb#ch0000003?line=19'>20</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m optimizer\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/sgd.py:69\u001b[0m, in \u001b[0;36mSGD.__init__\u001b[0;34m(self, params, lr, momentum, dampening, weight_decay, nesterov)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mif\u001b[39;00m nesterov \u001b[39mand\u001b[39;00m (momentum \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m dampening \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m     68\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNesterov momentum requires a momentum and zero dampening\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m \u001b[39msuper\u001b[39;49m(SGD, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(params, defaults)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/optimizer.py:48\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m defaultdict(\u001b[39mdict\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 48\u001b[0m param_groups \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(params)\n\u001b[1;32m     49\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(param_groups) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     50\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39moptimizer got an empty parameter list\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not iterable"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=5, gpus=1)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(pl.LightningModule):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.resnet = ResNet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
